{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fi-SFMkeQ6pB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04N5H-v5Q6pI",
        "outputId": "8f4079d5-8af2-40a9-af28-ce4b106782c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x159b8508250>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from model import *\n",
        "from train import *\n",
        "\n",
        "from test import test\n",
        "import string\n",
        "from utils import *\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "h7fHp_iNQ6pJ"
      },
      "outputs": [],
      "source": [
        "def load_data(X,Y,block_size,stop_char_index):\n",
        "    features = []\n",
        "    target = []\n",
        "    chars = []\n",
        "    def s_e(text,i,block_size,return_last_char=False):\n",
        "        start = i\n",
        "        end = i + block_size\n",
        "        start = min(len(text) - block_size,start)\n",
        "        end = min(len(text),end)\n",
        "        if return_last_char:\n",
        "            return text[start:end],text[end] if end<len(text) else stop_char_index\n",
        "        return text[start:end]\n",
        "    for f,t in zip(X,Y):\n",
        "        for i in range(len(f) - block_size):\n",
        "            features.append(s_e(f,i,block_size))\n",
        "            tt,c = s_e(t,i,block_size,return_last_char=True)\n",
        "            target.append(tt)\n",
        "            chars.append(c)\n",
        "    features = torch.tensor(features)\n",
        "    target = torch.tensor(target)\n",
        "    chars = torch.tensor(chars)\n",
        "    print(features.shape,target.shape,chars.shape)\n",
        "    return features,target,chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2BYnpgQ6pK",
        "outputId": "a0e34e4b-b7f6-4510-c481-cc2b761b45bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10297, 5]) torch.Size([10297, 5]) torch.Size([10297])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(52, 59, 10297)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def prepare_data(\n",
        "        src_path,\n",
        "        dst_path,\n",
        "        block_size,\n",
        "        start_token=\"$\",\n",
        "        end_token = \"^\",\n",
        "        add_start_end_tokens=True,\n",
        "        device=\"cpu\",\n",
        "        num_lines=None,\n",
        "        encoding=\"utf8\",\n",
        "    ):\n",
        "    src = load_txt(src_path,num_lines,encoding=encoding)\n",
        "    dst = load_txt(dst_path,num_lines,encoding=encoding)\n",
        "    \n",
        "    src_vocab = get_vocab(src) if not add_start_end_tokens else get_vocab(src,start=start_token,end=end_token)\n",
        "    dst_vocab = get_vocab(dst) if not add_start_end_tokens else get_vocab(dst,start=start_token,end=end_token)\n",
        "\n",
        "    src = [encode(txt,src_vocab) for txt in src]\n",
        "    dst = [encode(txt,dst_vocab) for txt in dst]\n",
        "\n",
        "    #src = list(filter(lambda l:len(l)==block_size,src))\n",
        "    #dst = list(filter(lambda l:len(l)==block_size,dst))\n",
        "\n",
        "\n",
        "    if add_start_end_tokens:\n",
        "        src = include_tokens(\n",
        "            src,\n",
        "            start_token_index=src_vocab.index(start_token),\n",
        "            amount=1\n",
        "        )\n",
        "        dst = include_tokens(\n",
        "            dst,\n",
        "            start_token_index=dst_vocab.index(start_token),\n",
        "            amount=block_size-1\n",
        "        )\n",
        "    src,dst,chars = load_data(src,dst,block_size,dst_vocab.index(end_token))\n",
        "    \n",
        "    return src.to(device=device),src_vocab,dst.to(device=device),dst_vocab,chars\n",
        "\n",
        "src_path = \"./resources/news-commentary-v9.fr-en.en\"\n",
        "dst_path = \"./resources/news-commentary-v9.fr-en.fr\"\n",
        "\n",
        "block_size = 5\n",
        "src,src_vocab,dst,dst_vocab,chars = prepare_data(\n",
        "    src_path,\n",
        "    dst_path,\n",
        "    block_size,\n",
        "    add_start_end_tokens=True,\n",
        "    num_lines=100,\n",
        ")\n",
        "encoder_vocab_size = len(src_vocab)\n",
        "decoder_vocab_size = len(dst_vocab)\n",
        "encoder_vocab_size,decoder_vocab_size,len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' gold'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode(src[99],src_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([' gold', '$late', 'latel', 'ately'], ['eur d', '$$$$e', '$$$et', '$$et '])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index,window =99,4\n",
        "decode_all(src[index:index+window],src_vocab),decode_all(dst[index:index+window],dst_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "79LbXwaJQ6pM"
      },
      "outputs": [],
      "source": [
        "N = 1\n",
        "n_embeddings = 32\n",
        "n_head = 4\n",
        "device = \"cpu\"\n",
        "\n",
        "model = AttentiveTranslator(\n",
        "    3,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    n_embeddings,\n",
        "    n_head,\n",
        "    src.shape,\n",
        "    dst.shape,\n",
        "    device=device\n",
        ").to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8237, 2060, 8237, 2060)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def split(X,y,train_size=.8,shuffle=True):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    return train_test_split(X,y,chars,train_size=train_size,shuffle=shuffle)\n",
        "src_train,src_valid,dst_train,dst_valid,chars_train,chars_val = split(src,dst)\n",
        "len(src_train),len(src_valid),len(dst_train),len(dst_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10297, 5]), torch.Size([10297, 5]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src.shape,dst.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab2zTeIbQ6pN",
        "outputId": "0289f6fb-3532-4a87-cc4a-1fc9cdd7e8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.607472896575928\n",
            "4.268762588500977\n",
            "4.295784950256348\n",
            "3.935128927230835\n",
            "3.672642469406128\n",
            "3.6724817752838135\n",
            "3.3058464527130127\n",
            "3.3122706413269043\n",
            "3.1836607456207275\n",
            "3.1797587871551514\n",
            "3.4907479286193848\n",
            "2.6631150245666504\n",
            "3.49959397315979\n",
            "3.0579090118408203\n",
            "3.169254779815674\n",
            "3.25533127784729\n",
            "3.028381109237671\n",
            "2.8590660095214844\n",
            "3.407579183578491\n",
            "2.9232866764068604\n",
            "3.071563243865967\n",
            "3.135579824447632\n",
            "3.4837944507598877\n",
            "2.642312526702881\n",
            "3.3064870834350586\n",
            "3.110717296600342\n",
            "3.2464845180511475\n",
            "3.1207122802734375\n",
            "2.9501264095306396\n",
            "3.1789543628692627\n",
            "2.8416242599487305\n",
            "2.7630410194396973\n",
            "3.208578109741211\n",
            "2.835777521133423\n",
            "2.7957053184509277\n",
            "2.93951153755188\n",
            "3.159423351287842\n",
            "3.176086187362671\n",
            "2.7470169067382812\n",
            "3.095226764678955\n",
            "3.086824417114258\n",
            "3.207108736038208\n",
            "3.0458788871765137\n",
            "2.5409460067749023\n",
            "2.715014934539795\n",
            "2.8203446865081787\n",
            "2.6028475761413574\n",
            "2.855919361114502\n",
            "3.0887460708618164\n",
            "2.548659563064575\n",
            "2.6404359340667725\n",
            "3.1062302589416504\n",
            "3.0034141540527344\n",
            "2.7324094772338867\n",
            "3.3017148971557617\n",
            "2.7800991535186768\n",
            "2.6748857498168945\n",
            "2.646691083908081\n",
            "2.718156337738037\n",
            "2.963712453842163\n",
            "2.988811492919922\n",
            "3.0885491371154785\n",
            "2.91851806640625\n",
            "2.639927625656128\n",
            "3.068470001220703\n",
            "2.969691276550293\n",
            "2.865032434463501\n",
            "2.8377325534820557\n",
            "3.126824140548706\n",
            "2.5747344493865967\n",
            "3.0029473304748535\n",
            "3.107893228530884\n",
            "3.0880284309387207\n",
            "2.6962592601776123\n",
            "2.9037179946899414\n",
            "3.0267460346221924\n",
            "2.859528064727783\n",
            "2.5919511318206787\n",
            "2.518101453781128\n",
            "2.859316349029541\n",
            "2.791416883468628\n",
            "2.8516836166381836\n",
            "2.897195816040039\n",
            "2.5362792015075684\n",
            "2.765505075454712\n",
            "2.6391026973724365\n",
            "2.7255144119262695\n",
            "3.5353808403015137\n",
            "2.6162195205688477\n",
            "2.6873536109924316\n",
            "2.6716089248657227\n",
            "2.9708945751190186\n",
            "2.936631917953491\n",
            "2.5060524940490723\n",
            "2.770176410675049\n",
            "2.5583736896514893\n",
            "2.9989051818847656\n",
            "2.972761869430542\n",
            "2.8043289184570312\n",
            "2.7011804580688477\n",
            "2.7180240154266357\n",
            "2.9232735633850098\n",
            "2.535348892211914\n",
            "2.5736334323883057\n",
            "2.6632914543151855\n",
            "2.7957282066345215\n",
            "2.3651089668273926\n",
            "2.584641218185425\n",
            "2.910478353500366\n",
            "2.9772231578826904\n",
            "2.7640538215637207\n",
            "3.031373977661133\n",
            "2.4501640796661377\n",
            "2.928724765777588\n",
            "2.4937868118286133\n",
            "2.5588371753692627\n",
            "2.4592530727386475\n",
            "2.465160846710205\n",
            "2.969954490661621\n",
            "2.4822640419006348\n",
            "2.685925245285034\n",
            "2.746467351913452\n",
            "2.9772746562957764\n",
            "2.7506394386291504\n",
            "2.186929702758789\n",
            "2.5716681480407715\n",
            "2.1423516273498535\n",
            "2.6323401927948\n",
            "2.4000823497772217\n",
            "2.5975630283355713\n",
            "2.6672303676605225\n",
            "2.5898795127868652\n",
            "3.325373888015747\n",
            "2.664809465408325\n",
            "2.38787841796875\n",
            "3.037450075149536\n",
            "2.5184264183044434\n",
            "2.6273183822631836\n",
            "2.9571359157562256\n",
            "2.5180375576019287\n",
            "2.5565810203552246\n",
            "2.6075680255889893\n",
            "2.488736391067505\n",
            "3.153404712677002\n",
            "2.4896352291107178\n",
            "2.5399229526519775\n",
            "2.559641122817993\n",
            "2.5092012882232666\n",
            "2.6343603134155273\n",
            "2.206005334854126\n",
            "2.724184036254883\n",
            "1.9106425046920776\n",
            "2.8339035511016846\n",
            "2.269044876098633\n",
            "2.283717393875122\n",
            "2.336040735244751\n",
            "2.2632110118865967\n",
            "2.7209370136260986\n",
            "2.715519428253174\n",
            "2.692591428756714\n",
            "2.8504092693328857\n",
            "2.919011116027832\n",
            "2.613389492034912\n",
            "2.288464307785034\n",
            "2.5390231609344482\n",
            "2.7118732929229736\n",
            "2.841926097869873\n",
            "2.5289230346679688\n",
            "2.7775700092315674\n",
            "2.6241445541381836\n",
            "2.433849573135376\n",
            "2.17817759513855\n",
            "2.6353182792663574\n",
            "2.6333694458007812\n",
            "2.1180830001831055\n",
            "2.4020493030548096\n",
            "2.259882688522339\n",
            "2.753523588180542\n",
            "2.5414369106292725\n",
            "2.494105339050293\n",
            "2.6839020252227783\n",
            "2.4242308139801025\n",
            "2.5368270874023438\n",
            "2.509078025817871\n",
            "2.533243417739868\n",
            "2.610450506210327\n",
            "2.2135977745056152\n",
            "2.669349193572998\n",
            "2.5149130821228027\n",
            "2.173017978668213\n",
            "2.6687679290771484\n",
            "2.5460572242736816\n",
            "2.7140960693359375\n",
            "2.5372402667999268\n",
            "2.4146196842193604\n",
            "2.936072587966919\n",
            "2.3619637489318848\n",
            "2.2414698600769043\n",
            "2.481809616088867\n",
            "2.710864543914795\n",
            "2.491150140762329\n",
            "2.534299850463867\n",
            "2.154378652572632\n",
            "2.132056713104248\n",
            "2.270684242248535\n",
            "2.5036911964416504\n",
            "2.158376932144165\n",
            "2.4138288497924805\n",
            "2.5536792278289795\n",
            "2.6385819911956787\n",
            "2.1161108016967773\n",
            "2.1705870628356934\n",
            "2.514078378677368\n",
            "2.6508967876434326\n",
            "2.581634998321533\n",
            "2.7735354900360107\n",
            "2.261164665222168\n",
            "2.3998794555664062\n",
            "2.6281025409698486\n",
            "2.46728253364563\n",
            "2.2820088863372803\n",
            "2.315169334411621\n",
            "2.5282974243164062\n",
            "2.164423942565918\n",
            "2.4586217403411865\n",
            "2.4545493125915527\n",
            "2.6259102821350098\n",
            "2.221372604370117\n",
            "2.209442615509033\n",
            "2.430202007293701\n",
            "2.4101579189300537\n",
            "2.4263153076171875\n",
            "2.4008278846740723\n",
            "2.4789204597473145\n",
            "2.299041271209717\n",
            "2.3532071113586426\n",
            "2.5020296573638916\n",
            "2.3407795429229736\n",
            "2.6709866523742676\n",
            "2.2523677349090576\n",
            "2.499349594116211\n",
            "2.5751867294311523\n",
            "2.1509673595428467\n",
            "2.416774034500122\n",
            "2.388115406036377\n",
            "2.383289098739624\n",
            "2.857851028442383\n",
            "2.5609676837921143\n",
            "2.413357973098755\n",
            "2.366178512573242\n",
            "2.4789533615112305\n",
            "2.5232295989990234\n",
            "2.121795654296875\n",
            "2.0203654766082764\n",
            "2.6042253971099854\n",
            "2.7439911365509033\n",
            "2.3280410766601562\n",
            "2.5113677978515625\n",
            "tensor(2.7104)\n"
          ]
        }
      ],
      "source": [
        "model = model.to(memory_format=torch.channels_last)\n",
        "optim = torch.optim.Adam(\n",
        "    model.parameters()\n",
        ")\n",
        "loss_fn = torch.nn.functional.cross_entropy\n",
        "train_loader = arrays_to_loader(src_train,dst_train,chars_train,batch_size=32)\n",
        "train(model,optim,loss_fn,1,train_loader,device,dst_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTXpINLyeScK",
        "outputId": "21c83f69-6c72-4c91-830d-7dbceec0d38a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9899)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "(dst_valid==test(model,src_valid,dst_valid)).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e\n",
            " \n",
            "d\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            " \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'e de de de de '"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from test import translate\n",
        "translate(\n",
        "    model,\n",
        "    \"hello there brother\",\n",
        "    block_size,\n",
        "    src_vocab,\n",
        "    dst_vocab,\n",
        "    device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DzzWY5__Q6pO",
        "outputId": "d081de5a-6270-4010-bdb7-d151b107bd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(125) tensor(90)\n",
            "^^^^à\n",
            "tensor(125) tensor(118)\n",
            "^^^àà\n",
            "tensor(125) tensor(146)\n",
            "^^ààà\n",
            "tensor(125) tensor(174)\n",
            "^àààà\n",
            "tensor(125) tensor(202)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n",
            "tensor(125) tensor(230)\n",
            "ààààà\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ààààààààààààààààààààààààà'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from test import translate\n",
        "translate(\n",
        "    model,\n",
        "    \"ffffffffffffffffffffffffffffff\",\n",
        "    block_size,\n",
        "    src_vocab,\n",
        "    dst_vocab,\n",
        "    device\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
