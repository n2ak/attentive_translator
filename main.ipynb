{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fi-SFMkeQ6pB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x170a036b210>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "from model import *\n",
        "from train import *\n",
        "\n",
        "from test import test\n",
        "import string\n",
        "from utils import *\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "src_path = \"./resources/news-commentary-v9.fr-en.en\"\n",
        "dst_path = \"./resources/news-commentary-v9.fr-en.fr\"\n",
        "N = 3\n",
        "n_embeddings = 32\n",
        "n_head = 4\n",
        "device = \"cpu\"\n",
        "block_size = 50\n",
        "start_token,end_token = \"[\",\"]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2BYnpgQ6pK",
        "outputId": "a0e34e4b-b7f6-4510-c481-cc2b761b45bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(68, 79, 161290)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src,src_vocab,dst,dst_vocab,chars = prepare_data(\n",
        "    src_path,\n",
        "    dst_path,\n",
        "    50,\n",
        "    add_start_end_tokens=True,\n",
        "    num_lines=1000,\n",
        "    start_token=start_token,\n",
        "    end_token=end_token,\n",
        "    remove_lines_containing_tokens=True\n",
        ")\n",
        "encoder_vocab_size = len(src_vocab)\n",
        "decoder_vocab_size = len(dst_vocab)\n",
        "encoder_vocab_size,decoder_vocab_size,len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for input,target,next_char in zip(decode_all(src,src_vocab),decode_all(dst,dst_vocab),decode(chars,dst_vocab)):\n",
        "#     print(input,\"   \",target,\"   ---->   \",next_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "79LbXwaJQ6pM"
      },
      "outputs": [],
      "source": [
        "model = AttentiveTranslator(\n",
        "    N,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    n_embeddings,\n",
        "    n_head,\n",
        "    src.shape,\n",
        "    dst.shape,\n",
        "    device=device\n",
        ").to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(129032, 32258, 129032, 32258, 129032, 32258)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_train,src_valid,dst_train,dst_valid,chars_train,chars_valid = split(src,dst,chars)\n",
        "len(src_train),len(src_valid),len(dst_train),len(dst_valid),len(chars_train),len(chars_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab2zTeIbQ6pN",
        "outputId": "0289f6fb-3532-4a87-cc4a-1fc9cdd7e8c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 2.2681405544281006: 100%|██████████| 4033/4033 [04:21<00:00, 15.40it/s]\n"
          ]
        }
      ],
      "source": [
        "model = model.to(memory_format=torch.channels_last)\n",
        "optim = torch.optim.Adam(\n",
        "    model.parameters()\n",
        ")\n",
        "loss_fn = torch.nn.functional.cross_entropy\n",
        "train_loader = arrays_to_loader(src_train,dst_train,chars_train,batch_size=32)\n",
        "epochs=1\n",
        "train(model,optim,loss_fn,epochs,train_loader,device,dst_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'le pars de pars de pars de pars de pars de pars de'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from test import translate\n",
        "translate(\n",
        "    model,\n",
        "    \"hello there brother\",\n",
        "    block_size,\n",
        "    src_vocab,\n",
        "    dst_vocab,\n",
        "    device,\n",
        "    start_char=start_token,\n",
        "    stop_char=end_token,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
