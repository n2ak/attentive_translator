{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy0oCQXNLMY8",
        "outputId": "5758346c-8a14-46c3-bd4a-c8b2a9a35f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/attentive_translator\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/n2ak/attentive_translator\n",
        "%cd attentive_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJdvlQG1LPUH",
        "outputId": "c945cc8a-18e9-4300-a130-bd28a26b3bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/attentive_translator\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi-SFMkeQ6pB",
        "outputId": "1e76b9e7-16f3-4510-ce85-761fe9456195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'attentive_translator'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattentive_translator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtest\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattentive_translator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'attentive_translator'"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "from model import *\n",
        "from train import *\n",
        "\n",
        "from attentive_translator.test import *\n",
        "import string\n",
        "from attentive_translator.utils import *\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LBmhexK9K__P"
      },
      "outputs": [],
      "source": [
        "src_path = \"./resources/news-commentary-v9.fr-en.en\"\n",
        "dst_path = \"./resources/news-commentary-v9.fr-en.fr\"\n",
        "N = 3\n",
        "n_embeddings = 32\n",
        "n_head = 4\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "block_size = 50\n",
        "start_token,end_token = \"[\",\"]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2BYnpgQ6pK",
        "outputId": "fb9ca95b-dec9-4e06-9c79-e0354647373e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53, 59, 12740)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src,src_vocab,dst,dst_vocab,chars = prepare_data(\n",
        "    src_path,\n",
        "    dst_path,\n",
        "    50,\n",
        "    add_start_end_tokens=True,\n",
        "    num_lines=100,\n",
        "    start_token=start_token,\n",
        "    end_token=end_token,\n",
        "    remove_lines_containing_tokens=True\n",
        ")\n",
        "encoder_vocab_size = len(src_vocab)\n",
        "decoder_vocab_size = len(dst_vocab)\n",
        "encoder_vocab_size,decoder_vocab_size,len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7XXMpzGK__R"
      },
      "outputs": [],
      "source": [
        "# for input,target,next_char in zip(decode_all(src,src_vocab),decode_all(dst,dst_vocab),decode(chars,dst_vocab)):\n",
        "#     print(input,\"   \",target,\"   ---->   \",next_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79LbXwaJQ6pM"
      },
      "outputs": [],
      "source": [
        "model = AttentiveTranslator(\n",
        "    N,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    32,\n",
        "    4,\n",
        "    src.shape,\n",
        "    dst.shape,\n",
        "    4,\n",
        "    4,\n",
        "    device=device\n",
        ").to(device=device)\n",
        "optim = torch.optim.Adam(\n",
        "    model.parameters()\n",
        ")\n",
        "load_weights(model,optim,\"./save_model.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ff': 3, 'N': 4}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = {\"ff\":3}\n",
        "a.update({\"N\":4})\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVma7dYWK__S",
        "outputId": "2242a9df-1a2f-4326-a5df-80d972ef3f2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1344076, 336020, 1344076, 336020, 1344076, 336020)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_train,src_valid,dst_train,dst_valid,chars_train,chars_valid = split(src,dst,chars)\n",
        "len(src_train),len(src_valid),len(dst_train),len(dst_valid),len(chars_train),len(chars_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab2zTeIbQ6pN",
        "outputId": "29694c36-cd42-4726-a40c-1253a9a8d4c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 1.8434727191925049: 100%|██████████| 42003/42003 [15:50<00:00, 44.19it/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32 * 2\n",
        "\n",
        "#model = model.to(memory_format=torch.channels_last)\n",
        "optim = torch.optim.Adam(\n",
        "    model.parameters()\n",
        ")\n",
        "loss_fn = torch.nn.functional.cross_entropy\n",
        "train_loader = arrays_to_loader(src_train,dst_train,chars_train,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iZq_vNZQEtn"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "train(model,optim,loss_fn,epochs,train_loader,device,dst_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oqtyWNc6K__T",
        "outputId": "6c2a9c4f-365d-400d-d17e-d74dc83bca81"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"la prisse de l'autre de l'autre de la prisse de la\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#from test import translate\n",
        "translate(\n",
        "    model,\n",
        "    \"its better to be quiet\".lower(),\n",
        "    block_size,\n",
        "    src_vocab,\n",
        "    dst_vocab,\n",
        "    device,\n",
        "    start_char=start_token,\n",
        "    stop_char=end_token,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
