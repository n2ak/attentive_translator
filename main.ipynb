{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Fi-SFMkeQ6pB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04N5H-v5Q6pI",
        "outputId": "8f4079d5-8af2-40a9-af28-ce4b106782c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x26622914270>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from model import *\n",
        "from train import *\n",
        "\n",
        "from test import test\n",
        "import string\n",
        "from utils import *\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "h7fHp_iNQ6pJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(X,Y,block_size):\n",
        "    features = []\n",
        "    target = []\n",
        "    def s_e(text,i,block_size):\n",
        "        start = i\n",
        "        end = i + block_size\n",
        "        start = min(len(text) - block_size,start)\n",
        "        end = min(len(text),end)\n",
        "        return text[start:end]\n",
        "    for f,t in zip(X,Y):\n",
        "        for i in range(len(f) - block_size + 1):\n",
        "            features.append(s_e(f,i,block_size))\n",
        "            target.append(s_e(t,i,block_size))\n",
        "    features = torch.tensor(features)\n",
        "    target = torch.tensor(target)\n",
        "    return features,target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "VgYYudLEQ6pK"
      },
      "outputs": [],
      "source": [
        "N = 1\n",
        "n_embeddings = 32\n",
        "block_size = 10\n",
        "n_head = 4\n",
        "device = \"cuda\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBxcBMp-bEmD",
        "outputId": "a9e2c8c6-b5a8-4c79-cd56-af7c78d4c1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src =[1,2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2BYnpgQ6pK",
        "outputId": "a0e34e4b-b7f6-4510-c481-cc2b761b45bd"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './training/news-commentary-v9.fr-en.fr'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[97], line 36\u001b[0m\n\u001b[0;32m     31\u001b[0m         dst \u001b[39m=\u001b[39m include_tokens(\n\u001b[0;32m     32\u001b[0m             dst,\n\u001b[0;32m     33\u001b[0m             end_token_index\u001b[39m=\u001b[39mdst_vocab\u001b[39m.\u001b[39mindex(end_token),\n\u001b[0;32m     34\u001b[0m         )\n\u001b[0;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice),src_vocab,dst\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice),dst_vocab\n\u001b[1;32m---> 36\u001b[0m src,src_vocab,dst,dst_vocab \u001b[39m=\u001b[39m prepare_data(\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./training/news-commentary-v9.fr-en.fr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     38\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./training/news-commentary-v9.fr-en.en\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     39\u001b[0m     block_size,\n\u001b[0;32m     40\u001b[0m     add_start_end_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     41\u001b[0m     num_lines\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     43\u001b[0m encoder_vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(src_vocab)\n\u001b[0;32m     44\u001b[0m decoder_vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dst_vocab)\n",
            "Cell \u001b[1;32mIn[97], line 11\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(src_path, dst_path, block_size, start_token, end_token, add_start_end_tokens, device, num_lines)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_data\u001b[39m(\n\u001b[0;32m      2\u001b[0m         src_path,\n\u001b[0;32m      3\u001b[0m         dst_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m         num_lines\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m     ):\n\u001b[1;32m---> 11\u001b[0m     src \u001b[39m=\u001b[39m load_txt(src_path,num_lines,encoding\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     12\u001b[0m     dst \u001b[39m=\u001b[39m load_txt(dst_path,num_lines,encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(src)\n",
            "File \u001b[1;32mf:\\per\\git\\translator\\utils.py:15\u001b[0m, in \u001b[0;36mload_txt\u001b[1;34m(path, num_lines, encoding)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_txt\u001b[39m(path, num_lines, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     16\u001b[0m         \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39msplitlines()[:num_lines]\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './training/news-commentary-v9.fr-en.fr'"
          ]
        }
      ],
      "source": [
        "def prepare_data(\n",
        "        src_path,\n",
        "        dst_path,\n",
        "        block_size,\n",
        "        start_token=\"$\",\n",
        "        end_token = \"^\",\n",
        "        add_start_end_tokens=True,\n",
        "        device=\"cpu\",\n",
        "        num_lines=None,\n",
        "    ):\n",
        "    src = load_txt(src_path,num_lines,encoding=None)\n",
        "    dst = load_txt(dst_path,num_lines,encoding=None)\n",
        "    print(src)\n",
        "    src_vocab = get_vocab(src) if not add_start_end_tokens else get_vocab(src,start=start_token,end=end_token)\n",
        "    dst_vocab = get_vocab(dst) if not add_start_end_tokens else get_vocab(dst,start=start_token,end=end_token)\n",
        "\n",
        "    src = [encode(txt,src_vocab) for txt in src]\n",
        "    dst = [encode(txt,dst_vocab) for txt in dst]\n",
        "\n",
        "    #src = list(filter(lambda l:len(l)==block_size,src))\n",
        "    #dst = list(filter(lambda l:len(l)==block_size,dst))\n",
        "\n",
        "\n",
        "\n",
        "    src,dst = load_data(src,dst,block_size)\n",
        "    if add_start_end_tokens:\n",
        "        src = include_tokens(\n",
        "            src,\n",
        "            start_token_index=src_vocab.index(start_token),\n",
        "        )\n",
        "        dst = include_tokens(\n",
        "            dst,\n",
        "            end_token_index=dst_vocab.index(end_token),\n",
        "        )\n",
        "    return src.to(device=device),src_vocab,dst.to(device=device),dst_vocab\n",
        "src,src_vocab,dst,dst_vocab = prepare_data(\n",
        "    \"./training/news-commentary-v9.fr-en.fr\",\n",
        "    \"./training/news-commentary-v9.fr-en.en\",\n",
        "    block_size,\n",
        "    add_start_end_tokens=True,\n",
        "    num_lines=1000\n",
        ")\n",
        "encoder_vocab_size = len(src_vocab)\n",
        "decoder_vocab_size = len(dst_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igbrxa2SbdLQ",
        "outputId": "843bd21b-1874-4a07-92ff-f21200fa1739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(151232, 151232)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(src),len(dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79LbXwaJQ6pM"
      },
      "outputs": [],
      "source": [
        "model = AttentiveTranslator(\n",
        "    1,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    n_embeddings,\n",
        "    n_head,\n",
        "    src.shape,\n",
        "    dst.shape,\n",
        "    device=device\n",
        ").to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "l8L05Od8YFrw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "183784"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(load_txt(\"./resources/news-commentary-v9.fr-en.en\",num_lines=None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GerlqmWeYhV2"
      },
      "outputs": [],
      "source": [
        "fr_content,en_content = \"\",\"\"\n",
        "with open(\"./training/news-commentary-v9.fr-en.fr\",\"r\") as f:\n",
        "  fr_content = f.read()\n",
        "with open(\"./training/news-commentary-v9.fr-en.en\",\"r\") as f:\n",
        "  en_content = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1jLbWVkZOUK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W_4H7LFYIBc"
      },
      "outputs": [],
      "source": [
        "!tar -xzf training-parallel-nc-v9.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab2zTeIbQ6pN",
        "outputId": "0289f6fb-3532-4a87-cc4a-1fc9cdd7e8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0002)\n"
          ]
        }
      ],
      "source": [
        "optim = torch.optim.Adam(\n",
        "    model.parameters()\n",
        ")\n",
        "loss_fn = torch.nn.functional.cross_entropy\n",
        "data_loader = arrays_to_loader(src,dst,32)\n",
        "train(model,optim,loss_fn,1,data_loader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK5-_R_iQ6pO",
        "outputId": "61e61f38-dffc-47ef-a5fe-4b6eb589acdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 4, 15, 14, 10, 14, 14, 14,  0, 37, 45, 29]], device='cuda:0'),\n",
              " tensor([[ 4, 15, 14, 10, 14, 14, 14,  0, 37, 45, 29]], dtype=torch.int32))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "model(src[0:1].to(device),dst[0:1].to(device)).argmax(-1),dst[0:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTXpINLyeScK",
        "outputId": "21c83f69-6c72-4c91-830d-7dbceec0d38a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 29)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_vocab.index(\"^\"),dst_vocab.index(\"^\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DzzWY5__Q6pO",
        "outputId": "d081de5a-6270-4010-bdb7-d151b107bd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n",
            "torch.Size([1, 11]) torch.Size([1, 11])\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'^^^^^^^^^^^^^^^^^^^'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def test(\n",
        "    model,\n",
        "    input_text,\n",
        "    block_size,\n",
        "    src_vocab,\n",
        "    dst_vocab,\n",
        "    max_tokens=100,\n",
        "    start_char=\"^\",\n",
        "    stop_char=\"$\"\n",
        "):\n",
        "    model.eval()\n",
        "    import torch\n",
        "    out_text = \"\"\n",
        "\n",
        "    for i in range(min(max_tokens, len(input_text) - block_size)):\n",
        "        text = input_text[i:block_size+i]\n",
        "        text = encode(text, src_vocab)\n",
        "        out = encode(start_char*len(text), dst_vocab)\n",
        "        input = torch.tensor([[30,*text]]).to(device)\n",
        "        output = torch.tensor([[*out,29]]).to(device)\n",
        "        print(input.shape,output.shape)\n",
        "        result = model(input, output)\n",
        "        char = result[:, -1, :].argmax(-1)\n",
        "        char = decode(char, dst_vocab)\n",
        "        if char == stop_char:\n",
        "            print(\"incountered\")\n",
        "            break\n",
        "        out_text += char\n",
        "\n",
        "    return out_text\n",
        "test(model,\"hello there how are you doing\",block_size,src_vocab,dst_vocab)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
